use golem_llm::error::{error_code_from_status, from_event_source_error, from_reqwest_error};
use golem_llm::event_source::EventSource;
use golem_llm::golem::llm::llm::Error;
use log::trace;
use reqwest::header::HeaderValue;
use reqwest::{Client, Method, Response};
use serde::de::DeserializeOwned;
use serde::{Deserialize, Serialize};
use std::fmt::Debug;

const BASE_URL: &str = "https://api.openai.com";

/// The OpenAI API client for creating model responses.
///
/// Based on https://platform.openai.com/docs/api-reference/responses/create
pub struct ResponsesApi {
    openai_api_key: String,
    client: Client,
}

impl ResponsesApi {
    pub fn new(openai_api_key: String) -> Self {
        let client = Client::builder()
            .build()
            .expect("Failed to initialize HTTP client");
        Self {
            openai_api_key,
            client,
        }
    }

    pub fn create_model_response(
        &self,
        request: CreateModelResponseRequest,
    ) -> Result<CreateModelResponseResponse, Error> {
        trace!("Sending request to OpenAI API: {request:?}");

        let response: Response = self
            .client
            .request(Method::POST, format!("{BASE_URL}/v1/responses"))
            .bearer_auth(&self.openai_api_key)
            .json(&request)
            .send()
            .map_err(|err| from_reqwest_error("Request failed", err))?;

        parse_response(response)
    }

    pub fn stream_model_response(
        &self,
        request: CreateModelResponseRequest,
    ) -> Result<EventSource, Error> {
        trace!("Sending request to OpenAI API: {request:?}");

        let response: Response = self
            .client
            .request(Method::POST, format!("{BASE_URL}/v1/responses"))
            .bearer_auth(&self.openai_api_key)
            .header(
                reqwest::header::ACCEPT,
                HeaderValue::from_static("text/event-stream"),
            )
            .json(&request)
            .send()
            .map_err(|err| from_reqwest_error("Request failed", err))?;

        trace!("Initializing SSE stream");

        EventSource::new(response)
            .map_err(|err| from_event_source_error("Failed to create SSE stream", err))
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateModelResponseRequest {
    pub input: Input,
    pub model: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_output_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Vec::is_empty")]
    pub tools: Vec<Tool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_choice: Option<String>,
    pub stream: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateModelResponseResponse {
    pub id: String,
    pub created_at: u64,
    pub error: Option<ErrorObject>,
    pub incomplete_details: Option<IncompleteDetailsObject>,
    pub status: Status,
    pub output: Vec<OutputItem>,
    pub usage: Option<Usage>,
    pub metadata: Option<serde_json::Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum OutputItem {
    #[serde(rename = "message")]
    Message {
        id: String,
        content: Vec<OutputMessageContent>,
        role: String,
        status: Status,
    },
    #[serde(rename = "function_call")]
    ToolCall {
        arguments: String,
        call_id: String,
        name: String,
        id: String,
        status: Status,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum OutputMessageContent {
    #[serde(rename = "output_text")]
    Text { text: String },
    #[serde(rename = "refusal")]
    Refusal { refusal: String },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorObject {
    pub code: String,
    pub message: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Status {
    #[serde(rename = "completed")]
    Completed,
    #[serde(rename = "failed")]
    Failed,
    #[serde(rename = "in_progress")]
    InProgress,
    #[serde(rename = "incomplete")]
    Incomplete,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IncompleteDetailsObject {
    pub reason: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum Input {
    TextInput(String),
    List(Vec<InputItem>),
}

/// An item representing part of the context for the response to be generated by the model.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum InputItem {
    #[serde(rename = "message")]
    InputMessage {
        /// A list of one or many input items to the model, containing different content types.
        content: InnerInput,
        /// The role of the message input. One of user, system, or developer.
        role: String,
    },
    #[serde(rename = "function_call")]
    ToolCall {
        /// A JSON string of the arguments to pass to the function.
        arguments: String,
        /// The unique ID of the function tool call generated by the model.
        call_id: String,
        /// https://platform.openai.com/docs/api-reference/responses/create
        name: String,
    },
    #[serde(rename = "function_call_output")]
    ToolResult {
        /// The unique ID of the function tool call generated by the model.
        call_id: String,
        /// A JSON string of the output of the function tool call.
        output: String,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum InnerInput {
    TextInput(String),
    List(Vec<InnerInputItem>),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum InnerInputItem {
    #[serde(rename = "input_text")]
    TextInput { text: String },
    #[serde(rename = "output_text")]
    TextOutput { text: String },
    #[serde(rename = "input_image")]
    ImageInput {
        image_url: String,
        #[serde(default)]
        detail: Detail,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub enum Detail {
    #[serde(rename = "auto")]
    #[default]
    Auto,
    #[serde(rename = "low")]
    Low,
    #[serde(rename = "high")]
    High,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum Tool {
    #[serde(rename = "function")]
    Function {
        name: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        description: Option<String>,
        #[serde(skip_serializing_if = "Option::is_none")]
        parameters: Option<serde_json::Value>,
        strict: bool,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    pub input_tokens: u32,
    pub input_tokens_details: InputTokensDetails,
    pub output_tokens: u32,
    pub output_tokens_details: OutputTokensDetails,
    pub total_tokens: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InputTokensDetails {
    pub cached_tokens: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OutputTokensDetails {
    pub reasoning_tokens: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResponseOutputTextDelta {
    pub content_index: u32,
    pub delta: String,
    pub item_id: String,
    pub output_index: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResponseOutputItemDone {
    pub item: OutputItem,
    pub output_index: u32,
}

fn parse_response<T: DeserializeOwned + Debug>(response: Response) -> Result<T, Error> {
    let status = response.status();
    if status.is_success() {
        let body = response
            .json::<T>()
            .map_err(|err| from_reqwest_error("Failed to decode response body", err))?;

        trace!("Received response from OpenAI API: {body:?}");

        Ok(body)
    } else {
        let body = response
            .text()
            .map_err(|err| from_reqwest_error("Failed to receive error response body", err))?;

        trace!("Received {status} response from OpenAI API: {body:?}");

        Err(Error {
            code: error_code_from_status(status),
            message: format!("Request failed with {status}"),
            provider_error_json: Some(body),
        })
    }
}
